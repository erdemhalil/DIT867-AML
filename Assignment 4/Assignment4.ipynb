{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88e88ac",
   "metadata": {
    "id": "f88e88ac"
   },
   "source": [
    "**Course Name：** DAT341 / DIT867 Applied Machine Learning\n",
    "\n",
    "**Examiner：** Richard Johansson (richajo@chalmers.se)\n",
    "\n",
    "**Assignment No.:** Assignment 4 - Software for neural network training\n",
    "\n",
    "**Due Date:** Mon, 26 Feb 2024 11:59pm\n",
    "\n",
    "**Group Name:** PA 4 3\n",
    "\n",
    "**Group Members:**\n",
    "- Natalia Alvarado (gusalvarsi@student.gu.se)\n",
    "- Erdem Halil (gushaliler@student.gu.se)\n",
    "- Xujie Li (guslixuf@student.gu.se)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0fea34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:30.873456Z",
     "start_time": "2024-02-25T13:34:30.151374Z"
    },
    "executionInfo": {
     "elapsed": 3872,
     "status": "ok",
     "timestamp": 1708864186234,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "5f0fea34"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wEaiRshArEFT",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:30.993350Z",
     "start_time": "2024-02-25T13:34:30.875037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1159,
     "status": "ok",
     "timestamp": 1708864189888,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "wEaiRshArEFT",
    "outputId": "af29c79e-ee70-4fe8-c3c6-582c0c6d15e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate https://www.cse.chalmers.se/~richajo/dit866/assignments/a4/data/a4_synthetic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56578f6f",
   "metadata": {
    "id": "56578f6f"
   },
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761f4d2",
   "metadata": {
    "id": "1761f4d2"
   },
   "source": [
    "Loading the synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacba01e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.004711Z",
     "start_time": "2024-02-25T13:34:30.995077Z"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1708864197333,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "aacba01e"
   },
   "outputs": [],
   "source": [
    "# You may need to edit the path, depending on where you put the files.\n",
    "data = pd.read_csv('a4_synthetic.csv')\n",
    "\n",
    "X = data.drop(columns='y').to_numpy()\n",
    "Y = data.y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166d6ba",
   "metadata": {
    "id": "b166d6ba"
   },
   "source": [
    "Training a linear regression model for this synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111ff34b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.480557Z",
     "start_time": "2024-02-25T13:34:31.005726Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2493,
     "status": "ok",
     "timestamp": 1708864272976,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "111ff34b",
    "outputId": "cbcb95e9-44d9-4352-a438-65f764eb4a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE = 0.7999661130823179\n",
      "Epoch 2: MSE = 0.017392390107906875\n",
      "Epoch 3: MSE = 0.009377418010839892\n",
      "Epoch 4: MSE = 0.009355326971438456\n",
      "Epoch 5: MSE = 0.009365440968904256\n",
      "Epoch 6: MSE = 0.009366989180952533\n",
      "Epoch 7: MSE = 0.009367207398577986\n",
      "Epoch 8: MSE = 0.009367238983974489\n",
      "Epoch 9: MSE = 0.009367243704122537\n",
      "Epoch 10: MSE = 0.009367244427185763\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "w_init = np.random.normal(size=(2, 1))\n",
    "b_init = np.random.normal(size=(1, 1))\n",
    "\n",
    "# We just declare the parameter tensors. Do not use nn.Linear.\n",
    "w = torch.tensor(w_init, requires_grad=True)\n",
    "b = torch.tensor(b_init, requires_grad=True)\n",
    "\n",
    "\n",
    "eta = 1e-2\n",
    "# A SGD optimizer with a learning rate of eta\n",
    "opt = torch.optim.SGD([w,b], lr=eta)\n",
    "\n",
    "t1_mse_per_epoch = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    sum_err = 0\n",
    "\n",
    "    for row in range(X.shape[0]):\n",
    "        x = torch.tensor(X[[row], :])\n",
    "        y = torch.tensor(Y[[row]])\n",
    "\n",
    "        # Forward pass.\n",
    "        # Compute predicted value for x\n",
    "        y_pred = x @ w + b\n",
    "        # Compute squared error loss\n",
    "        err = (y - y_pred)**2\n",
    "\n",
    "        # Backward and update.\n",
    "        # Compute gradients and then update the model.\n",
    "        opt.zero_grad()\n",
    "        err.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # For statistics.\n",
    "        sum_err += err.item()\n",
    "\n",
    "    mse = sum_err / X.shape[0]\n",
    "    print(f'Epoch {i+1}: MSE =', mse)\n",
    "    t1_mse_per_epoch.append(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f221d",
   "metadata": {
    "id": "ee3f221d"
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3191eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.484543Z",
     "start_time": "2024-02-25T13:34:31.481414Z"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1708864383902,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "1e3191eb"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        raise NotImplementedError('Unimplemented')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(type(self))\n",
    "\n",
    "\n",
    "class AdditionNode(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.left.backward(grad_output)\n",
    "        self.right.backward(grad_output)\n",
    "\n",
    "class SubtractionNode(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.left.backward(grad_output)\n",
    "        self.right.backward(-grad_output)\n",
    "\n",
    "class MatrixMultiplicationNode(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        left_grad = grad_output @ self.right.data.T\n",
    "        right_grad = self.left.data.T @ grad_output\n",
    "        self.left.backward(left_grad)\n",
    "        self.right.backward(right_grad)\n",
    "\n",
    "class PowerNode(Node):\n",
    "    def __init__(self, base, exponent):\n",
    "        self.base = base\n",
    "        self.exponent = exponent\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        base_grad = self.exponent * self.base.data**(self.exponent - 1) * grad_output\n",
    "        self.base.backward(base_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56be71d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.490268Z",
     "start_time": "2024-02-25T13:34:31.485346Z"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1708864419962,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "56be71d4"
   },
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "\n",
    "    # Constructor. Just store the input values.\n",
    "    def __init__(self, data, requires_grad=False, grad_fn=None):\n",
    "        self.data = data\n",
    "        self.shape = data.shape\n",
    "        self.grad_fn = grad_fn\n",
    "        self.requires_grad = requires_grad\n",
    "        self.grad = None\n",
    "\n",
    "    # So that we can print the object or show it in a notebook cell.\n",
    "    def __repr__(self):\n",
    "        dstr = repr(self.data)\n",
    "        if self.requires_grad:\n",
    "            gstr = ', requires_grad=True'\n",
    "        elif self.grad_fn is not None:\n",
    "            gstr = f', grad_fn={self.grad_fn}'\n",
    "        else:\n",
    "            gstr = ''\n",
    "        return f'Tensor({dstr}{gstr})'\n",
    "\n",
    "    # Extract one numerical value from this tensor.\n",
    "    def item(self):\n",
    "        return self.data.item()\n",
    "\n",
    "    # Operator +\n",
    "    def __add__(self, right):\n",
    "        # Call the helper function defined below.\n",
    "        return addition(self, right)\n",
    "\n",
    "    # Operator -\n",
    "    def __sub__(self, right):\n",
    "        # Call the helper function defined below.\n",
    "        return subtraction(self, right)\n",
    "\n",
    "    # Operator @\n",
    "    def __matmul__(self, right):\n",
    "        # Call the helper function defined below.\n",
    "        return matmul(self, right)\n",
    "\n",
    "    # Operator **\n",
    "    def __pow__(self, right):\n",
    "        # NOTE! We are assuming that right is an integer here, not a Tensor!\n",
    "        if not isinstance(right, int):\n",
    "            raise Exception('only integers allowed')\n",
    "        if right < 2:\n",
    "            raise Exception('power must be >= 2')\n",
    "        # Call the helper function defined below.\n",
    "        return power(self, right)\n",
    "\n",
    "\n",
    "    # Backward computations. Will be implemented in Task 4.\n",
    "    def backward(self, grad_output=None):\n",
    "        # We first check if this tensor has a grad_fn: that is, one of the\n",
    "        # nodes that you defined in Task 3.\n",
    "        if self.grad_fn is not None:\n",
    "            # If grad_fn is defined, we have computed this tensor using some operation.\n",
    "            if grad_output is None:\n",
    "                # This is the starting point of the backward computation.\n",
    "                # This will typically be the tensor storing the output of\n",
    "                # the loss function, on which we have called .backward()\n",
    "                # in the training loop.\n",
    "                self.grad_fn.backward(grad_output=1.0)\n",
    "            else:\n",
    "                # This is an intermediate node in the computational graph.\n",
    "                # This corresponds to any intermediate computation, such as\n",
    "                # a hidden layer.\n",
    "                self.grad = grad_output\n",
    "                self.grad_fn.backward(self.grad)\n",
    "        else:\n",
    "            # If grad_fn is not defined, this is an endpoint in the computational\n",
    "            # graph: learnable model parameters or input data.\n",
    "            if self.requires_grad:\n",
    "                # This tensor *requires* a gradient to be computed. This will\n",
    "                # typically be a tensor that holds learnable parameters.\n",
    "                self.grad = grad_output\n",
    "            else:\n",
    "                # This tensor *does not require* a gradient to be computed. This\n",
    "                # will typically be a tensor holding input data.\n",
    "                pass\n",
    "\n",
    "\n",
    "# A small utility where we simply create a Tensor object. We use this to\n",
    "# mimic torch.tensor.\n",
    "def tensor(data, requires_grad=False):\n",
    "    return Tensor(data, requires_grad)\n",
    "\n",
    "# We define helper functions to implement the various arithmetic operations.\n",
    "\n",
    "# This function takes two tensors as input, and returns a new tensor holding\n",
    "# the result of an element-wise addition on the two input tensors.\n",
    "def addition(left, right):\n",
    "    new_data = left.data + right.data\n",
    "    grad_fn = AdditionNode(left, right)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "def subtraction(left, right):\n",
    "    new_data = left.data - right.data\n",
    "    grad_fn = SubtractionNode(left, right)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "def matmul(left, right):\n",
    "    new_data = left.data @ right.data\n",
    "    grad_fn = MatrixMultiplicationNode(left, right)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "def power(left, right):\n",
    "    new_data = left.data ** right\n",
    "    grad_fn = PowerNode(left, right)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0f04c",
   "metadata": {
    "id": "36d0f04c"
   },
   "source": [
    "Some sanity checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2014827",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.494890Z",
     "start_time": "2024-02-25T13:34:31.491123Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1708864422002,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "f2014827",
    "outputId": "f9baa35f-836d-40d6-e98a-3892b30fa702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of addition: [[2. 3.]] + [[1. 4.]] = [[3. 7.]]\n",
      "Test of subtraction: [[2. 3.]] - [[1. 4.]] = [[ 1. -1.]]\n",
      "Test of power: [[1. 4.]] ** 2 = [[ 1. 16.]]\n",
      "Test of matrix multiplication: [[2. 3.]] @ [[-1. ]\n",
      " [ 1.2]] = [[1.6]]\n"
     ]
    }
   ],
   "source": [
    "# Two tensors holding row vectors.\n",
    "x1 = tensor(np.array([[2.0, 3.0]]))\n",
    "x2 = tensor(np.array([[1.0, 4.0]]))\n",
    "# A tensors holding a column vector.\n",
    "w = tensor(np.array([[-1.0], [1.2]]))\n",
    "\n",
    "# Test the arithmetic operations.\n",
    "test_plus = x1 + x2\n",
    "test_minus = x1 - x2\n",
    "test_power = x2 ** 2\n",
    "test_matmul = x1 @ w\n",
    "\n",
    "print(f'Test of addition: {x1.data} + {x2.data} = {test_plus.data}')\n",
    "print(f'Test of subtraction: {x1.data} - {x2.data} = {test_minus.data}')\n",
    "print(f'Test of power: {x2.data} ** 2 = {test_power.data}')\n",
    "print(f'Test of matrix multiplication: {x1.data} @ {w.data} = {test_matmul.data}')\n",
    "\n",
    "# Check that the results are as expected. Will crash if there is a miscalculation.\n",
    "assert(np.allclose(test_plus.data, np.array([[3.0, 7.0]])))\n",
    "assert(np.allclose(test_minus.data, np.array([[1.0, -1.0]])))\n",
    "assert(np.allclose(test_power.data, np.array([[1.0, 16.0]])))\n",
    "assert(np.allclose(test_matmul.data, np.array([[1.6]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c645c32",
   "metadata": {
    "id": "7c645c32"
   },
   "source": [
    "# Tasks 3 and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddeff43",
   "metadata": {
    "id": "9ddeff43",
    "tags": []
   },
   "source": [
    "**NOTE:** Moved Node cell above for easier execution of the whole notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1bb77-e869-4e08-8996-3674eed101e6",
   "metadata": {
    "id": "9cc1bb77-e869-4e08-8996-3674eed101e6"
   },
   "source": [
    "Sanity check for Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3276aba-4def-421b-b12e-bf0d7120f19e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.499135Z",
     "start_time": "2024-02-25T13:34:31.496862Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1708864559150,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "f3276aba-4def-421b-b12e-bf0d7120f19e",
    "outputId": "4dca3c9c-f10b-4d59-f9f4-0836f19cdb20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational graph top node after x + w1 + w2: <class '__main__.AdditionNode'>\n"
     ]
    }
   ],
   "source": [
    "x = tensor(np.array([[2.0, 3.0]]))\n",
    "w1 = tensor(np.array([[1.0, 4.0]]), requires_grad=True)\n",
    "w2 = tensor(np.array([[3.0, -1.0]]), requires_grad=True)\n",
    "\n",
    "test_graph = x + w1 + w2\n",
    "\n",
    "print('Computational graph top node after x + w1 + w2:', test_graph.grad_fn)\n",
    "\n",
    "assert(isinstance(test_graph.grad_fn, AdditionNode))\n",
    "assert(test_graph.grad_fn.right is w2)\n",
    "assert(test_graph.grad_fn.left.grad_fn.left is x)\n",
    "assert(test_graph.grad_fn.left.grad_fn.right is w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a9bfb-ea55-4bce-9356-4956316e1904",
   "metadata": {
    "id": "529a9bfb-ea55-4bce-9356-4956316e1904"
   },
   "source": [
    "Sanity check for Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32687661-a67d-4bef-9a90-7dabb93380a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.502419Z",
     "start_time": "2024-02-25T13:34:31.499994Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1708864579041,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "32687661-a67d-4bef-9a90-7dabb93380a2",
    "outputId": "7bcead71-1fc6-4319-cb67-656b7dc7a20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of loss w.r.t. w =\n",
      " [[5.6]\n",
      " [8.4]]\n"
     ]
    }
   ],
   "source": [
    "x = tensor(np.array([[2.0, 3.0]]))\n",
    "w = tensor(np.array([[-1.0], [1.2]]), requires_grad=True)\n",
    "y = tensor(np.array([[0.2]]))\n",
    "\n",
    "# We could as well write simply loss = (x @ w - y)**2\n",
    "# We break it down into steps here if you need to debug.\n",
    "\n",
    "model_out = x @ w\n",
    "diff = model_out - y\n",
    "loss = diff ** 2\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('Gradient of loss w.r.t. w =\\n', w.grad)\n",
    "\n",
    "assert(np.allclose(w.grad, np.array([[5.6], [8.4]])))\n",
    "assert(x.grad is None)\n",
    "assert(y.grad is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541cc295",
   "metadata": {
    "id": "541cc295"
   },
   "source": [
    "An equivalent cell using PyTorch code. Your implementation should give the same result for `w.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cabcc94a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.507567Z",
     "start_time": "2024-02-25T13:34:31.503220Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1708864589211,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "cabcc94a",
    "outputId": "199b546e-621b-46ee-8dbb-d27b21e4fd60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6000],\n",
       "        [8.4000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_x = torch.tensor(np.array([[2.0, 3.0]]))\n",
    "pt_w = torch.tensor(np.array([[-1.0], [1.2]]), requires_grad=True)\n",
    "pt_y = torch.tensor(np.array([[0.2]]))\n",
    "\n",
    "pt_model_out = pt_x @ pt_w\n",
    "pt_model_out.retain_grad() # Keep the gradient of intermediate nodes for debugging.\n",
    "\n",
    "pt_diff = pt_model_out - pt_y\n",
    "pt_diff.retain_grad()\n",
    "\n",
    "pt_loss = pt_diff ** 2\n",
    "pt_loss.retain_grad()\n",
    "\n",
    "pt_loss.backward()\n",
    "pt_w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5439b",
   "metadata": {
    "id": "d0b5439b"
   },
   "source": [
    "# Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b03a8c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.510424Z",
     "start_time": "2024-02-25T13:34:31.508321Z"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1708864770372,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "0b03a8c5"
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad = np.zeros_like(p.data)\n",
    "\n",
    "    def step(self):\n",
    "        raise NotImplementedError('Unimplemented')\n",
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr):\n",
    "        super().__init__(params)\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            p.data -= self.lr * p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85129b9b",
   "metadata": {
    "id": "85129b9b"
   },
   "source": [
    "Sanity check for Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacc6837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.539834Z",
     "start_time": "2024-02-25T13:34:31.511081Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1708864773067,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "bacc6837",
    "outputId": "34a8c941-5af7-437a-c011-853624424206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE = 0.7999661130823179\n",
      "Epoch 2: MSE = 0.017392390107906875\n",
      "Epoch 3: MSE = 0.009377418010839892\n",
      "Epoch 4: MSE = 0.009355326971438458\n",
      "Epoch 5: MSE = 0.009365440968904258\n",
      "Epoch 6: MSE = 0.009366989180952535\n",
      "Epoch 7: MSE = 0.009367207398577987\n",
      "Epoch 8: MSE = 0.00936723898397449\n",
      "Epoch 9: MSE = 0.009367243704122534\n",
      "Epoch 10: MSE = 0.009367244427185761\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "w_init = np.random.normal(size=(2, 1))\n",
    "b_init = np.random.normal(size=(1, 1))\n",
    "\n",
    "# We just declare the parameter tensors. Do not use nn.Linear.\n",
    "w = tensor(w_init, requires_grad=True)\n",
    "b = tensor(b_init, requires_grad=True)\n",
    "\n",
    "\n",
    "eta = 1e-2\n",
    "# A SGD optimizer with a learning rate of eta\n",
    "opt = SGD([w, b], lr=eta)\n",
    "\n",
    "t5_mse_per_epoch = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    sum_err = 0\n",
    "\n",
    "    for row in range(X.shape[0]):\n",
    "        x = tensor(X[[row], :])\n",
    "        y = tensor(Y[[row]])\n",
    "\n",
    "        # Forward pass.\n",
    "        # Compute predicted value for x\n",
    "        y_pred = x @ w + b\n",
    "        # Compute squared error loss\n",
    "        err = (y - y_pred)**2\n",
    "\n",
    "        # Backward and update.\n",
    "        # Compute gradients and then update the model.\n",
    "        opt.zero_grad()\n",
    "        err.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # For statistics.\n",
    "        sum_err += err.item()\n",
    "\n",
    "    mse = sum_err / X.shape[0]\n",
    "    print(f'Epoch {i+1}: MSE =', mse)\n",
    "    t5_mse_per_epoch.append(mse)\n",
    "\n",
    "# Check that the results are as expected. Will crash if there is a miscalculation.\n",
    "#assert(t1_mse_per_epoch == t5_mse_per_epoch)\n",
    "\n",
    "# The normal assertion will fail due to very small decimals.\n",
    "np.testing.assert_almost_equal(t1_mse_per_epoch, t5_mse_per_epoch, decimal=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bef171",
   "metadata": {
    "id": "28bef171"
   },
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hVAqV_dOt-7w",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.663228Z",
     "start_time": "2024-02-25T13:34:31.540567Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1708864779845,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "hVAqV_dOt-7w",
    "outputId": "578d3b00-7e9e-475d-f0b4-3ab3a1f7a860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate https://www.cse.chalmers.se/~richajo/dit866/assignments/a4/data/raisins.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da62980a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.934857Z",
     "start_time": "2024-02-25T13:34:31.664847Z"
    },
    "executionInfo": {
     "elapsed": 2473,
     "status": "ok",
     "timestamp": 1708864789610,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "da62980a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# You may need to edit the path, depending on where you put the files.\n",
    "a4data = pd.read_csv('raisins.csv')\n",
    "\n",
    "X = scale(a4data.drop(columns='Class'))\n",
    "Y = 1.0*(a4data.Class == 'Besni').to_numpy()\n",
    "\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(len(Y))\n",
    "X = X[shuffle]\n",
    "Y = Y[shuffle]\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "WdG4xnxU-5d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:31.942028Z",
     "start_time": "2024-02-25T13:34:31.935759Z"
    },
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1708867375535,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "WdG4xnxU-5d9"
   },
   "outputs": [],
   "source": [
    "class LinearNode(Node):\n",
    "    def __init__(self, input, weight, bias):\n",
    "        self.input = input\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input_grad = grad_output @ self.weight.data.T\n",
    "        weight_grad = self.input.data.T @ grad_output\n",
    "        bias_grad = np.sum(grad_output, axis=0)\n",
    "        self.input.backward(input_grad)\n",
    "        self.weight.backward(weight_grad)\n",
    "        self.bias.backward(bias_grad)\n",
    "\n",
    "class TanhNode(Node):\n",
    "    def __init__(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        tanh_grad = 1 - np.tanh(self.input.data)**2\n",
    "        self.input.backward(grad_output * tanh_grad)\n",
    "\n",
    "\n",
    "class SigmoidNode(Node):\n",
    "    def __init__(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        sigmoid_output = 1 / (1 + np.exp(-self.input.data))\n",
    "        sigmoid_grad = sigmoid_output * (1 - sigmoid_output)\n",
    "        self.input.backward(grad_output * sigmoid_grad)\n",
    "\n",
    "class BinaryCrossEntropyLossNode(Node):\n",
    "    def __init__(self, input, target):\n",
    "        self.input = input\n",
    "        self.target = target\n",
    "\n",
    "    def backward(self, grad_output, epsilon=1e-10):\n",
    "        input_clamped = np.clip(self.input.data, epsilon, 1 - epsilon)  # to avoid input.data being 0 or 1\n",
    "        input_grad = -(self.target.data / input_clamped - (1 - self.target.data) / (1 - input_clamped))\n",
    "        self.input.backward(input_grad)\n",
    "\n",
    "\n",
    "def linear(input, weight, bias):\n",
    "    new_data = input.data @ weight.data + bias.data\n",
    "    grad_fn = LinearNode(input, weight, bias)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "def tanh(input):\n",
    "    new_data = np.tanh(input.data)\n",
    "    grad_fn = TanhNode(input)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "def sigmoid(input):\n",
    "    new_data = 1 / (1 + np.exp(-input.data))\n",
    "    grad_fn = SigmoidNode(input)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "\n",
    "def binary_cross_entropy(input, target, epsilon=1e-10):\n",
    "    input_clamped = np.clip(input.data, epsilon, 1 - epsilon)  # to avoid input.data being 0 or 1\n",
    "    new_data = -target.data * np.log(input_clamped) - (1 - target.data) * np.log(1 - input_clamped)\n",
    "    grad_fn = BinaryCrossEntropyLossNode(input, target)\n",
    "    return Tensor(new_data, grad_fn=grad_fn)\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.weight1 = tensor(np.random.randn(input_dim, hidden_dim), requires_grad=True)\n",
    "        self.bias1 = tensor(np.zeros(hidden_dim), requires_grad=True)\n",
    "        self.weight2 = tensor(np.random.randn(hidden_dim, 1), requires_grad=True)\n",
    "        self.bias2 = tensor(np.zeros(1), requires_grad=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        h = tanh(linear(input, self.weight1, self.bias1))\n",
    "        output = sigmoid(linear(h, self.weight2, self.bias2))\n",
    "        return output\n",
    "\n",
    "def train(model, optimizer, Xtrain, Ytrain, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        input = tensor(Xtrain)\n",
    "        target = tensor(Ytrain.reshape(-1, 1))\n",
    "        output = model.forward(input)\n",
    "        loss = binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, X_test, y_test):\n",
    "    input = tensor(X_test)\n",
    "    output = model.forward(input)\n",
    "    predictions = np.round(output.data)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wT0F6hG8_Ao6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:34:32.106009Z",
     "start_time": "2024-02-25T13:34:31.942873Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1120,
     "status": "ok",
     "timestamp": 1708867377198,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "wT0F6hG8_Ao6",
    "outputId": "7ac2ab04-c5e8-4512-cd44-d4a81f872481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8833333333333333\n"
     ]
    }
   ],
   "source": [
    "model = Model(Xtrain.shape[1], 10)\n",
    "optimizer = SGD([model.weight1, model.bias1, model.weight2, model.bias2], lr=0.001)\n",
    "trained_model = train(model, optimizer, Xtrain, Ytrain, epochs=1000)\n",
    "accuracy = evaluate(trained_model, Xtest, Ytest)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "USYlFiel_NJB",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T13:35:11.078278Z",
     "start_time": "2024-02-25T13:34:32.106721Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268107,
     "status": "ok",
     "timestamp": 1708867645304,
     "user": {
      "displayName": "Xujie Li (Wilson Lee)",
      "userId": "08591637872298345186"
     },
     "user_tz": -60
    },
    "id": "USYlFiel_NJB",
    "outputId": "7085308e-e8d1-4a6b-96b5-b9e6d90a1644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 88.88888888888889%\n",
      "Best combination: (0.0001, 5, 500)\n"
     ]
    }
   ],
   "source": [
    "# Custom grid search\n",
    "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
    "hidden_dims = [5, 7, 10, 20]\n",
    "epochs = [100, 500, 1000, 10000]\n",
    "\n",
    "def grid_search(learning_rates, hidden_dims, epochs):\n",
    "    best_accuracy = 0\n",
    "    best_combination = None\n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for epoch in epochs:\n",
    "                model = Model(Xtrain.shape[1], hidden_dim)\n",
    "                optimizer = SGD([model.weight1, model.bias1, model.weight2, model.bias2], lr=lr)\n",
    "                trained_model = train(model, optimizer, Xtrain, Ytrain, epochs=epoch)\n",
    "                accuracy = evaluate(trained_model, Xtest, Ytest)\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_combination = (lr, hidden_dim, epoch)\n",
    "\n",
    "    return best_accuracy, best_combination\n",
    "\n",
    "best_accuracy, best_combination = grid_search(learning_rates, hidden_dims, epochs)\n",
    "print(f\"Best accuracy: {best_accuracy * 100}%\")\n",
    "print(f\"Best combination: {best_combination}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
